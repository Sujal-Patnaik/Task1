 Filling of NULL Values:
    Strategy: I found out Mean, Median and Mode of all columns having null values. For categorical data, I would fill with nodes.
    Experimentation: Thought of filling in the appropriate value from amongst mean, median and mode only in place of null values, except for 'higher' column
                     For filling in 'higher' I had thought to fill the null value as 'yes' if majority of 'schoolsup', 'famsup', 'paid', 'internet', 'address'
                     were 'yes'
    New_Strategy: 
                1. Made a correlation Heatmap between Fedu and Medu, and concluded that they are highly related.
                   If Medu = 0, 1, 2, 3, 4 I filled the null values of Fedu as 2, 1, 2, 3, 4 respectively.
                   Deduced this from a stacked bar graph between Fedu and Medu.
                2. For 'higher' plotted a correlation matrix between 'schoolsup', 'famsup', 'paid', 'internet', 'address' and 'higher'
                   Hence deduced that they were little related, So filled the null values it with its mode.
                3. For rest of them I applied the same old strategy.
Finding out the meanings of Feature_1, Feature_2 and Feature_3:
     Experimentation: I thought that Feature_1 was probably age.
     Strategy to verify experimentation:  I deduced this using the .describe() function, since the mean was nearly 17 and max value was 22 and 
                                          min value was 15. Majority of the students were below 20. So this was probably the age of high-school going students.
                                          I plotted the box plots of Feature_1 with absences,health,traveltime and freetime. 
                                          We cannot draw much conclusions from the traveltime, Health and Freetime graphs since the distribution is almost uniform till 19 and 
                                          there are very less students of age 20,21,22 so nothing much can be concluded from a low number of datapoints.
                                          For the absences graph we can see that majority of the students have relatively low absences till 19 years of age, whereas for 
                                          higher ages like 20 and 21 years they have higher absences, probably due to more responsibilities for making income for their family.
                                          So this supports that the Feature_1 column is age of the students.We can finally conclude that the Feature_1 column is age of the students.
     For Feature_2 I was unable to guess anything so followed the below strategy.
     Strategy to find out Feature_2: 1. First of all used .describe() function to find mean,median,mode,maximum and minimum. Feature_2 could have taken only 4 values
                                        that are 1,2,3,4.
                                     2. Plotted a countplot with absences. But for each value of Feature_2 absences had the same type of distribution.
                                     3. Plotted a stacked percentage bar graph with Health, Dalc, goout, freetime, famrel, failures, G3, G3 and G1.
                                        Couldnt conclude anything much from health,dalc,goout,freetime and famrel. But failures had clearly an inverse relationship with 
                                        Feature_2. Also students with higher Feature_2 had higher chances of having higher G1,G2,G3. 
                                     4. Plotted a correlation matrix between Feature_2, G1,G2,G3 and Failures which was also inline with the conclusions from the graphs
     Experimental guess: Finally after this thought that Feature_2 was probably IQ or study_hour rating. 
     Strategy to verify Experimentatal guess: We can finally conclude that Feature_2 is clearly related to academics, probably IQ or study hours. 
                                              Now the distribution of students with respect to Feature_2 is skewed and not a normal distribution. 
                                              The distribution is more towards the 1 and 2 and very less for 3 and 4. So we can rule out that Feature_2 is
                                              not IQ rating, since for IQ rating we would have expected more percentage of students in the middle that is 2 and 3 and very less percentage in 1 and 4.
                                              But that is not the case. So Feature_2 probably represents study hours rating since most of the students would be studying less and moderately. 
                                              Very few students study excessively.
     Feature_3: For this I did the exact same plots as done with Feature_2. Since we can see that Feature 3 is highly related to Dalc and goout,
                as Feature_3 increases both of them increases therefore Feature_3 is most probably Extroverism.


Insightful Questions Regarding Dataset.
1. HOW DOES PARENTS EDUCATION AFFECTS STUDENTS EDUCATION. (Give a Qualitative Analysis.)
   ans: Tabulated the mean grades with Father's and Mother's Education. Also plotted Average G3 with Father's and Mother's Education. Finally concluded that
        with increase in both mother's and father's education there is an increase in Grades of students. So Parent's education affects students grades in a positive way.
2. HOW DOES GENDER PLAYS A ROLE IN STUDENTS GRADE. DO FEMALES TEND TO STUDY BETTER THAN MALES OR VICE VERSA.
   ans: Plotted box plots of G3, G2, G1 with sex(M/F). It seemed that for Females all G1,G2 and G3 had higher median and mean than Males. 
        But this is a very localized dataset and we cannot comment much in general.
3. HOW DOES IT AFFECTS THE STUDENTS WHOSE PARENTS ARE APART?
   ans: I tabulated the the mean values of 'famrel','Dalc','health','absences','freetime','goout' with Pstatus. Also made a bar graph. I concluded 
        that students whose parents are apart have very high absences. There is very little difference in famrel, Dalc, health, freetime and goout. 
        But still students whose parents are apart have little bit less freetime and less goout than whose parents are together. 
        Students with apart parents also have lower average family relations.
        I also tabulated a values of yes and no counts against Pstatus with 'romantic','activities','higher','internet','paid','nursery'. 
        Here we can conclude that students whose Pstatus is T, tend to have higher percentage of students interested in activities, higher education 
        as well as availability of internet. Also 43% of students whose parents are apart have romantic relationship where as only 35% of studens whose 
        parents are together have romantic relationship, this indicates that whose parents are apart probably have a feeling of loneliness and that is why 
        more interested in romantic relationship. This helps in concluding that students whose parents are apart generally become lonely and there is a negative impact on them.
4. WHAT KIND OF DIFFERENCES IN EDUCATION FACILITIES DO STUDENTS IN RURAL AND URBAN AREAS GET?
   ans: I plotted a bar graph showing the percentages of yes and no for a particular property among : 'romantic', 'activities', 'higher', 'internet', 'paid', 'nursery', 'schoolsup', 'famsup'
        in a particular address that is Urban(U) and Rural(R). Here we can conclude that Rural and Urban areas get almost the same facilities in terms of Education like famsup,schoolsup,nursery,paid extra classes and higher education aspiration and activities.
        The only but a very a crucial thing that Rural are students are behind urban students is internet. Above 80% of urban students have internet access whereas only 65% of rural students have internet access.


Model Training For Romantic Relationship Prediction
       Strategy: Since we need to predict the status of Romantic Relationship I had to use a classifier model and not a regression model. 
                 So I rejected Linear Regression to be used in this. But I could have used Naive Bayes Classifier, Logistic Regression and also RandomForest Classifier.
       Experimentation: I initially thought of applying the Naive Bayes Classifier Model. 
       Strategy to Implement Naive Bayes :
                       1. Data Preprocessing & Feature Engineering:The romantic column is converted to binary values (yes → 1, no → 0).
                                                                   All categorical columns are one-hot encoded to prepare them for modeling.
                                                                   Features that are strongly correlated with each other (correlation > 0.4) are grouped together,
                                                                   and their average is taken to create new combined features — this helps reduce redundancy in the dataset.
                       2. Correlation-Based Feature Selection: To focus on features that matter, only those with a correlation greater than ±0.08 with the target are kept.
                                                               The top 10 positive and negative correlations with the romantic label are visualized in a heatmap — this
                                                               helps spot which features are most strongly linked to being in a relationship.
                       3. Polynomial Transformation & Scaling: Numeric features are expanded using polynomial transformations (degree 2) to let the model capture more complex, non-linear patterns.
                                                               These transformed features are also standardized using StandardScaler, which helps Gaussian Naive Bayes work more effectively.
                       4. Modeling with Gaussian Naive Bayes: A pipeline is created that includes preprocessing steps and the GaussianNB classifier.
                                                              The model is trained using 5-fold cross-validation, and data is split using a stratified
                                                              approach to ensure the class distribution is maintained in both training and test sets.
                       5. Model Evaluation & Limitations: Performance is evaluated using accuracy, a confusion matrix, and a classification report.
                                                          However, since Naive Bayes doesn’t provide feature importance scores, 
                                                          it's harder to explain which features influenced the model’s decisions the most — making it 
                                                          less interpretable than tree-based models.
                       ** Naive Bayes had a very good accuracy of 70%. It also had a good precision of 71% for no and 67% for yes.
                       ** Since Naive Bayes is less interpretable so to proceed further in task which demanded interpretation I have used Logistic Regression and Ranom Forest Classifier.
                       IMP NOTE: Even though Naive Bayes has been discarded but the X and y that are defined from the df on the basis of the threshold value, it is 
                                 still being used in the further code of Logistic Regression and Random Forest Classifier. So before running the code block of 
                                 Logistic Regression it is necessary to run the Naive Bayes Code Block.
        Strategy of Implementation of Logistic Regression and Random Forest Classifier:
                       1. Data Splitting for Training & Testing: The dataset is split into 80% for training and 20% for testing. Stratified sampling is used so that the class distribution 
                          (e.g., percentage of students in a relationship) stays balanced in both sets.
                       2. Model Training with Hyperparameter Tuning: Two models — Logistic Regression and Random Forest — are trained using GridSearchCV. 
                                                                     This helps automatically find the best combination of hyperparameters using 5-fold cross-validation for each model.
                       3. Pipeline with Scaling: Each model is placed in a pipeline that first applies StandardScaler to normalize the features. 
                                                 This ensures the models work well, especially Logistic Regression, which is sensitive to feature scaling.
                       4. Model Evaluation and Visualization: After training, predictions are made on the test set. Performance is measured using accuracy, a classification report, and a confusion matrix.
                                                              To make results easier to understand, confusion matrices are also shown as heatmaps.
                       5. Best Model Selection: The test accuracies of both models are compared.Whichever model performs best is chosen as the final model and printed as the top performer.

                       ** Logistic Regression had almost the same accuracy as Random Forest Classifier of around 62%. But Logistic Regression had a better confusion matrix than Random Forest.
                       


Model Reasoning and Interpretation: 
                    * At first I had plotted a heatmap of all the features currently there in X and romantic. Hence from that I had decided to make a decision boundary 
                      plot between Feature_1(age) and absences.
        Strategy of implementation of decision boundary plot: 
                    1. Pick Two Features:Choose two numeric features from the dataset (e.g., "Feature_1" and "absences"). These will form the 2D space for visualization.
                    2. Extract and Fit the Model: Select just the two features from the dataset and fit your classifier (like Logistic Regression or Random Forest) on this data.
                    3. Create a Mesh Grid: Use numpy.meshgrid to create a grid of values that span the range of your two features. This helps simulate the full feature space.
                    4. Predict Across the Grid: Run the trained model on each point in the mesh to predict class labels, which form the decision boundary.
                    5. Plot the Boundary and Points: Use matplotlib.pyplot.contourf to shade the background based on predicted classes.
                                                     Overlay the actual data points using plt.scatter.
                    6. Add Labels and Accuracy: Label the axes with the selected features and display model accuracy on the plot title for quick performance insight.

        Strategy to Use SHAP for Model Explainability:
                    1. Pick the Best Model : Use the best-performing model from GridSearchCV (including its preprocessing steps via pipeline).
                    2. Extract Components : Pull out the scaler and the actual classifier from the pipeline.
                    3. Scale the Data : Apply the same scaler (used during training) to the training features.
                    4. Prepare DataFrame : Convert the scaled data back to a DataFrame with original feature names — SHAP needs this format for plotting.
                    5. Choose the Right SHAP Explainer: Use TreeExplainer for tree models like Random Forest. Use LinearExplainer for linear models like Logistic Regression.
                    6. Compute SHAP Values : Run the explainer on the scaled data to get feature contributions for each prediction.
                    7. Visualize Feature Impact : Use shap.summary_plot to show how each feature influences the model output across all samples.

        Strategy to Interpret Individual Predictions Using SHAP:
                    1. Scale Test Data: Apply the same scaler (from training) to the test features.
                    2. Make Predictions: Use the trained classifier to predict on the scaled test set.
                    3. Run SHAP on Test Data: Pass the scaled test set to the SHAP explainer to get detailed explanation objects for each sample.
                    4. Pick Examples to Explain: Find the first test sample predicted as "Yes" (1). Find the first test sample predicted as "No" (0).
                    5. Visualize Local Explanations : Use SHAP waterfall plots to see how individual features influenced each of the two selected predictions.
                                                      This helps you understand what drove the model’s decision for a specific student.

      **** FINAL CONCLUSION : The factors that rally drive the relationship prediction are : Feature_1(age), absences, grades and guardian(other). All these can be 
                              concluded from the shap summary plot.

















                    
















